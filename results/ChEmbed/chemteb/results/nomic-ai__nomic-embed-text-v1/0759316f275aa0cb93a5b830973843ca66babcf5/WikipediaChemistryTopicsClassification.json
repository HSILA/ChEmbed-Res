{
  "dataset_revision": "d8fb355db2248f95df8ea410a43aa1db1ee96ba4",
  "task_name": "WikipediaChemistryTopicsClassification",
  "mteb_version": "2.7.8",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.857482,
            "f1": 0.861748,
            "f1_weighted": 0.856034,
            "precision": 0.863379,
            "precision_weighted": 0.858565,
            "recall": 0.863876,
            "recall_weighted": 0.857482,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.88361,
            "f1": 0.881352,
            "f1_weighted": 0.882407,
            "precision": 0.882225,
            "precision_weighted": 0.885805,
            "recall": 0.884982,
            "recall_weighted": 0.88361,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.864608,
            "f1": 0.859971,
            "f1_weighted": 0.863625,
            "precision": 0.858862,
            "precision_weighted": 0.867873,
            "recall": 0.866352,
            "recall_weighted": 0.864608,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.871734,
            "f1": 0.871673,
            "f1_weighted": 0.871423,
            "precision": 0.876836,
            "precision_weighted": 0.879743,
            "recall": 0.875519,
            "recall_weighted": 0.871734,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.874109,
            "f1": 0.875164,
            "f1_weighted": 0.87248,
            "precision": 0.87531,
            "precision_weighted": 0.876306,
            "recall": 0.880487,
            "recall_weighted": 0.874109,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.826603,
            "f1": 0.823518,
            "f1_weighted": 0.824788,
            "precision": 0.825521,
            "precision_weighted": 0.828612,
            "recall": 0.827271,
            "recall_weighted": 0.826603,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.881235,
            "f1": 0.884595,
            "f1_weighted": 0.879236,
            "precision": 0.888042,
            "precision_weighted": 0.886291,
            "recall": 0.889346,
            "recall_weighted": 0.881235,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.874109,
            "f1": 0.876233,
            "f1_weighted": 0.872872,
            "precision": 0.87706,
            "precision_weighted": 0.874247,
            "recall": 0.877981,
            "recall_weighted": 0.874109,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.833729,
            "f1": 0.827525,
            "f1_weighted": 0.826357,
            "precision": 0.84007,
            "precision_weighted": 0.842847,
            "recall": 0.839721,
            "recall_weighted": 0.833729,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.874109,
            "f1": 0.870727,
            "f1_weighted": 0.873241,
            "precision": 0.8702,
            "precision_weighted": 0.875475,
            "recall": 0.874339,
            "recall_weighted": 0.874109,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.864133,
        "f1": 0.86325,
        "f1_weighted": 0.862246,
        "precision": 0.86575,
        "precision_weighted": 0.867576,
        "recall": 0.867987,
        "recall_weighted": 0.864133,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.864133,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 13.591781377792358,
  "kg_co2_emissions": null
}