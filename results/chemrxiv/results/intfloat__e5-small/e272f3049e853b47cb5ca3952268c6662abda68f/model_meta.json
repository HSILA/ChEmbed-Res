{"loader_kwargs": {"model_prompts": {"query": "query: ", "document": "passage: "}, "trust_remote_code": true}, "name": "intfloat/e5-small", "revision": "e272f3049e853b47cb5ca3952268c6662abda68f", "release_date": "2024-02-08", "languages": ["eng-Latn"], "n_parameters": 33000000, "memory_usage_mb": 127.0, "max_tokens": 512.0, "embed_dim": 384, "license": "mit", "open_weights": true, "public_training_code": null, "public_training_data": null, "framework": ["Sentence Transformers", "PyTorch", "ONNX", "safetensors"], "reference": "https://huggingface.co/intfloat/e5-small", "similarity_fn_name": "cosine", "use_instructions": true, "training_datasets": ["NQHardNegatives", "mMARCO-NL", "NanoNQRetrieval", "MSMARCO", "MSMARCOHardNegatives", "NQ-NL", "NQ-PL", "MSMARCO-PL", "NanoMSMARCORetrieval", "NQ"], "adapted_from": "sentence-transformers/all-MiniLM-L6-v2", "superseded_by": null, "modalities": ["text"], "model_type": ["dense"], "citation": "\n@article{wang2022text,\n  title={Text Embeddings by Weakly-Supervised Contrastive Pre-training},\n  author={Wang, Liang and Yang, Nan and Huang, Xiaolong and Jiao, Binxing and Yang, Linjun and Jiang, Daxin and Majumder, Rangan and Wei, Furu},\n  journal={arXiv preprint arXiv:2212.03533},\n  year={2022}\n}\n", "contacts": null, "loader": "sentence_transformers_loader", "is_cross_encoder": false}